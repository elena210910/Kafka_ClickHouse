# Kafka_ClickHouse

# Descripci√≥n del proyecto

Este proyecto est√° dise√±ado para cargar datos a trav√©s de la API de una compa√±√≠a cervecera estadounidense en la base de datos 
ClickHouse a trav√©s de Kafka en tiempo real.

## Realizaci√≥n

![](https://github.com/elena210910/Kafka_ClickHouse/blob/main/OIP.jfif)

1. Verificamos el API (https://api.openbrewerydb.org/breweries)
   con una solicitud GET para entender la estructura del archivo. 
   Sabemos que los datos se devuelven en formato JSON. 
   Para esto, escribir√© un [c√≥digo en Python](https://github.com/elena210910/Kafka_ClickHouse/blob/main/Code_test_python) y revisar√© los datos.

Los datos obtenidos:

![](https://github.com/elena210910/Kafka_ClickHouse/blob/main/screen1.PNG)

2. En los datos obtenidos podemos ver los nombres de las columnas,
   seleccionar las columnas necesarias y escribir el [c√≥digo para enviarlos a Kafka.](https://github.com/elena210910/Kafka_ClickHouse/blob/main/Code_to_kafka)
   
    ***Bibliotecas utilizadas***
  
     **json:** Serializaci√≥n y deserializaci√≥n de datos JSON.
  
     **requests:** Realizaci√≥n de solicitudes HTTP al API.
  
     **kafka (KafkaProducer):**  Env√≠o de datos a Kafka.

   

   
  

4. Ejecutemos nuestro archivo y luego revisemos la interfaz de Kafka. Veremos nuestro t√≥pico all√≠.
   Actualmente, Kafka almacenar√° temporalmente nuestro archivo - 'breweriess', asegurando que los datos no 
   se pierdan si el consumer no est√° disponible.
    No especificamos el consumer en el c√≥digo, as√≠ que el resto lo har√© a trav√©s de ClickHouse.

   ![](https://github.com/elena210910/Kafka_ClickHouse/blob/main/screen2.PNG)




 5. Clickhouse.
    

    ![](https://github.com/elena210910/Kafka_ClickHouse/blob/main/R.jfif)


    Ahora vamos a hablar de ClickHouse, una base de datos columnar, muy r√°pida y optimizada para OLAP.
    Su rendimiento se debe a sus motores de almacenamiento. Para obtener datos de Kafka, utilizaremos un motor especial.
    Os presento a ENGINE = Kafka üöÄüéÜ

    *Primero*, [crearemos una tabla](https://github.com/elena210910/Kafka_ClickHouse/blob/main/tabla_raw_breweries) (raw_breweries) que extraiga datos de Kafka,
    utilizando el puerto configurado, el nombre del t√≥pico y asegur√°ndonos de que las columnas coincidan.

    *Segundo*. Las tablas que utilizan el motor Kafka, como en nuestro caso raw_breweries, no se pueden manejar ni consultar como una tabla normal.
    [Crearemos una segunda tabla](https://github.com/elena210910/Kafka_ClickHouse/blob/main/tabla_breweries_data) (breweries_data) con la que podamos trabajar posteriormente.
    En esta tabla, si es necesario, se pueden cambiar los tipos de datos de las columnas. 
    Lo importante es que est√©n correctamente especificados, de lo contrario, los datos de la tabla raw_breweries no se transferir√°n.

    *Y lo √∫ltimo*, y muy importante. Crearemos una [vista materializada](https://github.com/elena210910/Kafka_ClickHouse/blob/main/MATERIALIZED_VIEW) (materialized view) que transferir√° 
      los datos de raw_breweries a breweries_data.


    **Observaremos los resultados!**

En la interfaz, en la carpeta de consumidores, apareci√≥ el nombre del grupo de consumidores ('clickhouse_one') que especificamos en 
la primera tabla en ClickHouse **raw_breweries**, lo que significa que los datos se cargaron en la tabla gracias a ese motor ENGINE = Kafka.

![](https://github.com/elena210910/Kafka_ClickHouse/blob/main/screen3.PNG)





Y ahora, miremos nuestras tablas y escribamos una consulta simple a la tabla con la que trabajaremos posteriormente:
Select DISTINCT (*)
FROM breweries_data bd
LIMIT 10


![](https://github.com/elena210910/Kafka_ClickHouse/blob/main/screen4.PNG)




**¬°Voil√†! Todo funciona, todos los datos se cargaron en la tabla principal. Si es necesario, los datos pueden seguir llegando en tiempo real con la ayuda de Kafka. ¬°Integrar ClickHouse con Kafka es muy conveniente!**

üöÄüéâ
  








   
